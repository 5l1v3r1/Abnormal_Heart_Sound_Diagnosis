{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkmu1oX_qoxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, Conv1D, GRU\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import ConvLSTM2D\n",
        "from matplotlib import pyplot\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "FV = loadmat('/content/drive/My Drive/pcg.mat')\n",
        "X_train = FV['FeatureVector']\n",
        "print(X_train.shape)\n",
        "Y_train = FV['group']\n",
        "Y_train = Y_train.transpose()\n",
        "print(Y_train.shape)\n",
        "FVT = loadmat('/content/drive/My Drive/pcgT.mat')\n",
        "X_test = FVT['FV']\n",
        "print(X_test.shape)\n",
        "Y_test = FVT['GP']\n",
        "Y_test = Y_test.transpose()\n",
        "print(Y_test.shape)\n",
        "pass_band = [25*2/2000, 800*2/2000]\n",
        "b, a = butter(1, pass_band, 'bandpass')\n",
        "for i, sig in enumerate(X_train):\n",
        "    X_train[i, :] = filtfilt(b, a, X_train[i, :])\n",
        "for j, sig2 in enumerate(X_test):\n",
        "    X_test[j, :] = filtfilt(b, a, X_test[j, :])\n",
        "X = np.concatenate((X_train, X_test))\n",
        "Y = np.concatenate((Y_train, Y_test))\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "X = X.reshape(3541, 10000, 1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42)\n",
        "# fit and evaluate a model\n",
        "Y_train = to_categorical(Y_train, num_classes=2)\n",
        "Y_test = to_categorical(Y_test, num_classes=2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "    # define model\n",
        "    verbose, epochs, batch_size = 1, 5000, 512\n",
        "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "    # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "    n_steps, n_length = 100, 100\n",
        "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
        "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
        "    print(trainX.shape)\n",
        "    print(testX.shape)\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv1D(filters=8, kernel_size=5, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "    model.add(TimeDistributed(Conv1D(filters=4, kernel_size=5, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "    model.add(TimeDistributed(Conv1D(filters=2, kernel_size=5, activation='relu'), input_shape=(None,n_length,n_features)))    \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))  \n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    # print(model.summary())\n",
        "    # fit network\n",
        "    #model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "    model.fit(x=trainX, y=trainy, batch_size=batch_size, epochs=epochs, verbose=verbose, callbacks=None, validation_data=(testX, testy),\n",
        "              use_multiprocessing=True)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "    print(scores)\n",
        "    m, s = mean(scores), std(scores)\n",
        "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "    # load data\n",
        "    # repeat experiment\n",
        "    scores = list()\n",
        "    for r in range(repeats):\n",
        "        score = evaluate_model(X_train, Y_train, X_test, Y_test)\n",
        "        score = score * 100.0\n",
        "        print('>#%d: %.3f' % (r+1, score))\n",
        "        scores.append(score)\n",
        "    # summarize results\n",
        "    summarize_results(scores)\n",
        "\n",
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
